# PI_M5_V1 - MLOps Pipeline (Monitoreo y Data Drift)

Proyecto de MLOps para predicciÃ³n de riesgo crediticio con:

- API de inferencia en FastAPI
- App de monitoreo en Streamlit
- DetecciÃ³n de data drift con PSI (Population Stability Index)
- Predicciones batch con exportaciÃ³n de resultados

## Arquitectura actual

```text
mlops_pipeline/
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ src/
    â”œâ”€â”€ model_deploy.py
    â”œâ”€â”€ model_monitoring.py
    â”œâ”€â”€ model_training_evaluation.py
    â”œâ”€â”€ ft_engineering.py
    â”œâ”€â”€ cargar_datos.py
    â”œâ”€â”€ models/
    â”‚   â”œâ”€â”€ RandomForestClassifier_optuna.pkl
    â”‚   â””â”€â”€ feature_names.pkl
    â””â”€â”€ predicciones/ (generadas al hacer predicciones por lotes en Streamlit)
        â””â”€â”€ predicciones_batch_YYYYMMDD_HHMMSS.csv
```

## Componentes

### 1) API de inferencia (`src/model_deploy.py`)

Endpoints disponibles:

- `POST /predict`: predicciÃ³n individual
- `POST /predict_batch`: predicciÃ³n por lote

La API carga:

- `src/models/RandomForestClassifier_optuna.pkl`
- `src/models/feature_names.pkl`

## 2) Monitoreo (`src/model_monitoring.py`)

La app Streamlit tiene 4 tabs:

- **Graficas**: distribuciÃ³n de predicciones y comparaciÃ³n con referencia
- **Data Drift**: PSI por variable, alertas y evoluciÃ³n temporal
- **Logs**: vista tabular + descarga CSV desde la UI
- **Predicciones por Lotes**: carga CSV, consulta API batch y exporta resultados

### Comportamiento importante del monitoreo

- El drift se calcula con split base del dataset:
  - **Referencia:** 80%
  - **Actual:** 20%
- Los archivos generados por batch en `src/predicciones/` **no** se usan para cÃ¡lculo de drift.
- Cada ejecuciÃ³n batch crea un archivo en:
  - `src/predicciones/predicciones_batch_YYYYMMDD_HHMMSS.csv`

## 3) Resumen de archivos clave de modelado

### `src/ft_engineering.py`

Este mÃ³dulo concentra todo el preprocesamiento y devuelve los datasets listos para entrenar/evaluar:

- Carga y limpia datos (nulos, outliers y consistencia de tipos).
- Crea features derivadas de negocio (grupo de edad, variables temporales, total de crÃ©ditos, etc.).
- Evita leakage eliminando variables que no deben entrar al modelo.
- Ordena temporalmente y aplica split 80/20 sin shuffle.
- Aplica pipeline de Feature-engine (imputaciÃ³n + encoding) y devuelve:
  - `X_train_processed_fe`, `X_test_processed_fe`, `y_train`, `y_test`.

### `src/model_training_evaluation.py`

Este mÃ³dulo entrena, compara y optimiza modelos de clasificaciÃ³n:

- Define tres candidatos: RandomForest, XGBoost y CatBoost.
- EvalÃºa con `TimeSeriesSplit` y mÃ©tricas de clasificaciÃ³n, priorizando clase 0 (`recall_0` y `f1_0`).
- Selecciona el mejor modelo base con criterio robusto (`mean - std`).
- Ejecuta optimizaciÃ³n de hiperparÃ¡metros con Optuna sobre el mejor candidato.
- Entrena el modelo final, guarda artefactos en `src/models/`:
  - modelo `*_optuna.pkl`
  - `feature_names.pkl` (orden de columnas esperado por la API).

## 4) Data Drift (PSI)

InterpretaciÃ³n usada en la app:

- `PSI < 0.10` â†’ ðŸŸ¢ Bajo
- `0.10 <= PSI <= 0.25` â†’ ðŸŸ¡ Moderado
- `PSI > 0.25` â†’ ðŸ”´ Alto

Variables temporales excluidas del anÃ¡lisis de drift:

- `mes_prestamo`
- `anio_prestamo`
- `dia_semana_prestamo`
- `fin_de_mes`

## InstalaciÃ³n y ejecuciÃ³n local

### 1) Instalar dependencias

```bash
pip install -r requirements.txt
```

### 2) Entrenar (si necesitÃ¡s regenerar modelos)

```bash
cd src
python model_training_evaluation.py
```

### 3) Levantar API

```bash
cd src
uvicorn model_deploy:app --reload
```

API docs:

- `http://localhost:8000/docs`

### 4) Levantar Streamlit

```bash
cd src
streamlit run model_monitoring.py
```

UI:

- `http://localhost:8501`

## EjecuciÃ³n con Docker (solo API)

### Build de imagen

```bash
docker build -t mlops-api .
```

### Run del contenedor

```bash
docker run -d --name mlops-api-container -p 8000:8000 mlops-api
```

### Verificar

- API: `http://localhost:8000/docs`

> Streamlit sigue ejecutÃ¡ndose localmente (host) en `8501` y consume la API en `localhost:8000`. Solamente consume el endpoint de predicciones por lotes `/predict_batch`

## Flujo recomendado de uso

1. Levantar API (`uvicorn` o Docker)
2. Levantar Streamlit
3. Visualizar tabs de **Graficas** y **Data Drift**
4. Ir a **Predicciones por Lotes**
5. Cargar un CSV con columnas esperadas por el modelo
6. Ejecutar predicciones
7. Descargar resultados desde la UI

## Notas de mantenimiento

- Si cambiÃ¡s features del modelo, regenerÃ¡ `feature_names.pkl` y el `.pkl` del modelo.
- Si cambian puertos/host de API, actualizÃ¡ las URLs de consumo en `model_monitoring.py`.
- La carpeta `src/predicciones/` actÃºa como salida de corridas batch.
